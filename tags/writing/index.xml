<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>writing on ssaraf</title>
    <link>https://ssaraf.com/tags/writing/</link>
    <description>Recent content in writing on ssaraf</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 31 Aug 2022 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://ssaraf.com/tags/writing/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Why I disagree with effective altruism</title>
      <link>https://ssaraf.com/ea/</link>
      <pubDate>Wed, 31 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://ssaraf.com/ea/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Effective altruism&lt;/strong&gt; is a &amp;ldquo;research field, which aims to identify the worldâ€™s most pressing problems and the best solutions to them, and a practical community that aims to use those findings to do good.&amp;rdquo; [1]&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve long felt that EA was a bit silly, at least for a normal person. But I didn&amp;rsquo;t have a good framework for why I felt that way.&lt;/p&gt;
&lt;p&gt;I recently went on a walk with a friend involved in EA, and I thought the discussion was extremely thought-provoking (in a literal sense - my thoughts were provoked!). It helped elucidate to me what felt wrong about the movement and its philosophy, and I thought that in classic EA spirit I&amp;rsquo;d write it down and solicit some feedback. [2]&lt;/p&gt;
&lt;h2 id=&#34;bow-to-the-fashionistas&#34;&gt;Bow to the fashionistas.&lt;/h2&gt;
&lt;p&gt;First I should say, as all who criticize EA must, that EAs are wonderful people, that I have tremendous respect for what they stand for. I say that because I have to say it.&lt;/p&gt;
&lt;p&gt;Because that is the first part of the problem. EA is &lt;em&gt;so&lt;/em&gt; popular. Almost every intellectual I know either benignly or actively subscribes to a subset of the EA philosophy. Rich, famous people fund Open Philanthropy and GiveWell. I&amp;rsquo;m just a regular shmoe, what &lt;em&gt;right&lt;/em&gt; do I have to criticize what the world thinks is correct and good and moral?&lt;/p&gt;
&lt;p&gt;Paul Graham has a nice piece about fashions, though fortunately for him he&amp;rsquo;s now the most fashionable person in the valley [3]. As Paul describes, the problem with fashions is that lots of people follow them, and even if the fashion being followed is nominally self-reflective, it may miss a glaring, obvious mistake that&amp;rsquo;s only visible in retrospect. EA&amp;rsquo;s popularity should be a cause for suspicion, not a celebration.&lt;/p&gt;
&lt;p&gt;More practically, for those who disagree or don&amp;rsquo;t follow a fashion, the way to deal with it is to &lt;em&gt;not engage&lt;/em&gt;. What I am writing this for, exactly? The best case scenario is that almost no one reads it. The worst case is it gets popular, and the mob comes after me.&lt;/p&gt;
&lt;p&gt;This isn&amp;rsquo;t a direct criticism of EA, of course. But it means that real criticisms of EA are either unlikely to be written or, maybe more frighteningly, not as likely to be thought about. People will &lt;em&gt;assume&lt;/em&gt; that EA is the correct moral philosophy, rather than litigating it fully as I believe it deserves. Perhaps that&amp;rsquo;s part of the reason why many critiques of EA tend to be of the flavor &amp;ldquo;assume EA is right, here&amp;rsquo;s a specific thing they do that I disagree with&amp;rdquo; rather than &amp;ldquo;EA is wrong, here&amp;rsquo;s why&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Just to provide a tangible example here, it looks like Scott Alexander has strong opinions about EA, but isn&amp;rsquo;t publishing them because they&amp;rsquo;re too spicy. [4] He&amp;rsquo;s SSC! It should be worrying that someone so popular and prominent among &amp;ldquo;rationalists&amp;rdquo; is worried that his hot take might be too hot.&lt;/p&gt;
&lt;h2 id=&#34;come-all-ye-faithful&#34;&gt;Come all ye faithful&lt;/h2&gt;
&lt;p&gt;EAs like to think of themselves as rational, rigorous, and quantitative. They conduct and read studies about what donations are most effective. They are, at least in their minds, Richard Feynmans, except with altruistic endeavors instead of physics.&lt;/p&gt;
&lt;p&gt;But something doesn&amp;rsquo;t seem quite right. For example, if you ask an EA how much you should donate a year, they suggest roughly 10% of your income, regardless of how much you earn.&lt;/p&gt;
&lt;p&gt;Does that number sound familiar? It sounds a little bit like a tithe. Where&amp;rsquo;s the quantification?&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s what I would expect from a true &amp;ldquo;effective altruist&amp;rdquo;: I&amp;rsquo;d expect them to do a rough analysis of their existing audience - perhaps western hemisphere intellectuals of the upper middle class. Then they&amp;rsquo;d generate a histogram of typical incomes of people in the EA movement. Then they&amp;rsquo;d plot that vs incremental marginal utility. And I&amp;rsquo;d expect them to suggest a percentage of income that changes depending on that marginal utility calculation.&lt;/p&gt;
&lt;p&gt;After all, EAs have gone through the trouble of quantifying the suffering of a chicken in a cage for an expected value calculation. [5] Why haven&amp;rsquo;t they done rigorous quantification of the input to a charity, not just the output?&lt;/p&gt;
&lt;p&gt;Because EA sometimes looks a lot more like a religion than an intellectual movement.&lt;/p&gt;
&lt;p&gt;I grew up in a small town in Louisiana, a very religious place. I&amp;rsquo;m used to people trying to convert me to their faith. I see the same elements in many EAs.&lt;/p&gt;
&lt;p&gt;There is the worship of it, the acceptance of all the core tenets, and the debates over clerical details. There is an assumption that they alone know the truth, and those who disagree should be evangelized to and brought into the fold. Prominent ideas, which on the surface seem to disagree with their philosophy get subsumed or merged into EA, like Saturnalia becoming Christmas.&lt;/p&gt;
&lt;p&gt;The main difference is that EAs &lt;em&gt;worship&lt;/em&gt; quantification. They worship correctness, at least in some sense. Which makes it a little bit difficult to criticize them, in what Michael Neilson describes as &amp;ldquo;EA judo&amp;rdquo; - many criticisms of EA turn into something that makes EA stronger. [6]&lt;/p&gt;
&lt;p&gt;For example, one group of EAs tends to prioritize short-term interventions that have quantifiable amounts of utility. Another group of EAs tend to prioritize long-term interventions which have unknown utility (perhaps they mediate the future risk of the apocalypse by a small, unknown, percentage). You might &lt;em&gt;expect&lt;/em&gt; that an effective altruist organization would have a paradigm for how to prioritize between these two. Isn&amp;rsquo;t the whole point that we measure the utility of any intervention, compare them, and then make a &lt;em&gt;choice&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;No&amp;hellip;remember the EA philosophy - anything you see that isn&amp;rsquo;t EA, seen from another angle, can become EA. Can&amp;rsquo;t quantify the impact of a long-term intervention? That&amp;rsquo;s okay - it still might be effective!&lt;/p&gt;
&lt;p&gt;Open Philanthropy, a very prominent effective altruism organization, actually has two leaders, one who focuses on short-term quantitative interventions, and the other focuses on long-term abstract ones.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m not saying that&amp;rsquo;s the wrong choice. But I think I have gripes with describing this as effective altruism. EA doesn&amp;rsquo;t seem to be that useful of a paradigm if you&amp;rsquo;re willing to mold it and reshape it this flexibly. It doesn&amp;rsquo;t seem like there&amp;rsquo;s a good rationale for having both of these classes of investment, and if you can&amp;rsquo;t distinguish which one is better, how do I know which to contribute to?&lt;/p&gt;
&lt;h2 id=&#34;the-goal-is-not-to-maximize-quantifiable-utility&#34;&gt;The goal is not to maximize quantifiable utility&lt;/h2&gt;
&lt;p&gt;Initially, EA&amp;rsquo;s goal appeared to be a version of utilitarianism. Measure what good you can do in utils for intervention A, compare it to interventions B, C, and D, and put money into the causes in decreasing order of maximal utility.&lt;/p&gt;
&lt;p&gt;But most EA organizations don&amp;rsquo;t do this exactly. They hedge by putting money into the top 10 interventions, even if more money could go to the top 1 by depriving the other 9.&lt;/p&gt;
&lt;p&gt;This is a small sin but I find it to be significant. EAs have a lot of capital, but they don&amp;rsquo;t seem to deploy it in a way that shows they believe in their effectiveness calculations. If you believe that A is strictly better than B, why in the world are you funding B? It doesn&amp;rsquo;t appear to be the case, for example, that cause A is oversubscribed or has achieved diminishing returns.&lt;/p&gt;
&lt;p&gt;I could nitpick at a hundred of these types of things. For example, &amp;ldquo;EA marketing&amp;rdquo; is also a cause on the list of things EA organizations implicitly fund, but I&amp;rsquo;m not sure I&amp;rsquo;ve seen the calculation of how many utils their marketing is worth relative to buying more bed nets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The sheer &lt;em&gt;number&lt;/em&gt; of causes that most prominent EA organizations pursue (whether they call them causes or not) means that a &amp;ldquo;utility-based&amp;rdquo; analysis does not appear to explain their actions.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Instead, at least some EAs see certain interventions as having uncertainty and risk. Holden Karnofsky writes about some of that &amp;ldquo;hits-based giving&amp;rdquo;&amp;hellip; there are interventions, many of them, where you are not certain about the exact amount of value it will have, but it is possible that by investing in a portfolio of such interventions, one or two will make up for the rest in terms of value provided. [7]&lt;/p&gt;
&lt;p&gt;That leads to EAs funding all sorts of (in my opinion) kooky ideas. For example, animal welfare is funded at 3x the amount that climate change is. [8]&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssaraf.com/ea_cause_pri.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The problem is that debating between, say, animal welfare and climate change is it&amp;rsquo;s no longer a quantitative analysis of what provides the most good. Instead, we have a qualitative analysis of something like &amp;ldquo;if animals are beings with consciousness, the value of preventing their suffering would be high, thus even if the aforementioned is unlikely we will fund this to maximize expected utility&amp;rdquo;. We are not investing in the best charities, we are portfolio managers investing in a bunch of things where at least one might hit it out of the park, diversifying our risk away.&lt;/p&gt;
&lt;p&gt;I actually think that rationale is pretty reasonable, but it makes it hard to reason about which things deserve a &amp;ldquo;judgment call&amp;rdquo; vs which things are measured directly in QALYs.&lt;/p&gt;
&lt;h2 id=&#34;uncertainty-and-error-bars-on-interventions&#34;&gt;Uncertainty and error bars on interventions&lt;/h2&gt;
&lt;p&gt;This brings me to my central issue with effective altruism. EAs are, with the left hand, the rigorous quantitative measurers they portray themselves to be. That means any short-term intervention is evaluated with objectivity. Food banks are a &lt;em&gt;mistake&lt;/em&gt;. &lt;em&gt;Never&lt;/em&gt; contribute to local radio. Think of the utils! Think of the 100x or 1000x multiple you can get by reducing global poverty with that incremental dollar!&lt;/p&gt;
&lt;p&gt;And yet, on the right hand, they are qualitative estimators of distant future events, immeasurable risks, and unquantifiable value. They see the proto-souls of chickens and mice and pigs and say, per their Drake equation-like calculations, that they are more valuable than other interventions. [9]&lt;/p&gt;
&lt;p&gt;And so, in aggregate, the population of EAs is spending their time on health in third world countries and animal welfare, while there is poop at their doorstep (literally - I live in San Francisco, remember). There is limited awareness of that cognitive dissonance.&lt;/p&gt;
&lt;p&gt;Let me try to tease it apart a bit more.&lt;/p&gt;
&lt;h2 id=&#34;why-regular-people-are-not-likely-to-subscribe-to-ea&#34;&gt;Why regular people are not likely to subscribe to EA&lt;/h2&gt;
&lt;p&gt;It should be obvious that as income goes up, there is diminishing marginal utility in each extra dollar. Dustin Moskovitz can contribute a hundred grand, or even a million dollars, and hardly break a sweat.&lt;/p&gt;
&lt;p&gt;But Joe Sixpack (yes he&amp;rsquo;s back from 2008), who still has a mortgage, and a car note, really would appreciate that extra hundred bucks. I&amp;rsquo;ve already discussed my general surprise that the EA community doesn&amp;rsquo;t have a calculator where expected personal utility goes down as income goes up because it could make their donation recommendations far more specific and useful.&lt;/p&gt;
&lt;p&gt;But how should we think about personal marginal utility vs global?&lt;/p&gt;
&lt;h2 id=&#34;i-care-about-myself-a-lot-more-than-i-care-about-an-anonymous-person&#34;&gt;I care about myself a lot more than I care about an anonymous person.&lt;/h2&gt;
&lt;p&gt;I know, it&amp;rsquo;s selfish. But a hundred starving people in China won&amp;rsquo;t have nearly as much impact on me as my nephew burning his hand on the stove. Personal utility matters a lot! None of us is God, looking upon each of our human subjects as children to be gardened and nurtured. We are biased.&lt;/p&gt;
&lt;p&gt;I care about myself, my family, my community, my city, and my country. I don&amp;rsquo;t think that&amp;rsquo;s weird or some kind of weakness. Personal utility is not just a way to look at the world, it&amp;rsquo;s &lt;em&gt;the&lt;/em&gt; way that everyone (including, I suspect,  those who profess they are EA) truly lives.&lt;/p&gt;
&lt;p&gt;Even those people who have gone above and beyond, donating kidneys, dedicating their entire working lives to helping people around the world&amp;hellip;those people still live, to a first approximation, upper middle class lives in predominantly coastal cities. They still care about their kid&amp;rsquo;s education and spend time thinking about it (sometimes more time than those bed nets).&lt;/p&gt;
&lt;p&gt;My thesis: &lt;strong&gt;we are all maximizing our personal utility&lt;/strong&gt;, it&amp;rsquo;s just that one way of maximizing it is to &lt;em&gt;feel&lt;/em&gt; like the work you&amp;rsquo;re doing matters in some way&amp;hellip;perhaps as part of a global movement to do the quantifiably right thing.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s the old argument - are you helping grandma cross the street because &lt;em&gt;it&lt;/em&gt; is good or because &lt;em&gt;it makes you feel good&lt;/em&gt;? The latter is arguably a selfish endeavor.&lt;/p&gt;
&lt;h2 id=&#34;ea-dramatically-underestimates-the-value-of-maximizing-personal-utility&#34;&gt;EA dramatically underestimates the value of maximizing personal utility&lt;/h2&gt;
&lt;p&gt;Remember Dustin? He didn&amp;rsquo;t get rich by working on EA in his early 20s. He had an upper-middle-class upbringing, went to Harvard, then started Facebook. Instead of working on charitable work upfront, he spent his time (and money) at a company building something interesting and valuable. He then went on to start Asana, &lt;em&gt;another&lt;/em&gt; company that was interesting and valuable.&lt;/p&gt;
&lt;p&gt;Dustin is maximizing global utility &lt;em&gt;now&lt;/em&gt; because there&amp;rsquo;s unlikely to be much left in terms of personal utility. That makes sense!&lt;/p&gt;
&lt;p&gt;But he&amp;rsquo;s surrounded by a much larger group of people who are contributing to maximizing global utility in favor of personal utility as part of the effective altruist movement. They are predominantly upper middle class, intellectual, and high potential&amp;hellip;pretty much the same position that Dustin was in before he started his first company.&lt;/p&gt;
&lt;p&gt;The difference is that instead of making a discontinuous, risky bet, these people are optimizing the charitable giving of people who&amp;rsquo;ve already made that bet successfully. Or they&amp;rsquo;re taking a pseudo-random percentage of their income and donating it every year. With all due respect for the value of what they&amp;rsquo;re doing, I think that&amp;rsquo;s a mistake.&lt;/p&gt;
&lt;h2 id=&#34;recommendation-for-readers-who-havent-collapsed-from-boredom&#34;&gt;Recommendation for readers who haven&amp;rsquo;t collapsed from boredom&lt;/h2&gt;
&lt;p&gt;I hypothesize that there are roughly three categories of people relevant to EA:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The rich people - these folks have completely diminishing personal marginal utility, so they should spend their money on things that have the highest impact. They should do EA, but remember that long-termist EA isn&amp;rsquo;t measured quite the same way. Think killer robots are going to take over the world? Fine - spend money and fix that. Think it&amp;rsquo;s a super virus? Asteroid? China&amp;rsquo;s hegemony? Whatever you think is most important, there is probably a case to be made that EA is a fit. The one exception is if you want to change something specific in your local community right now, in which case you&amp;rsquo;re arguably not making an EA investment, you&amp;rsquo;re making one of personal utility (which I think is still commendable, though pure EAs would not agree).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The intellectuals - these folks are the brilliant thinkers and contributors that are part of the EA and/or rationalist movement. They have a strong moral compass, a good sense of how to weigh things of quantitative value, and (as good as anyone) the ability to ballpark qualitative value. They can&amp;rsquo;t compare the two that well. They can&amp;rsquo;t sum personal utility with the global utility to see why a local food bank might sometimes be a good interventional choice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The normies - these people are working hard to get to the next level. While charity from them is admirable, their personal utility is so much larger than it is for the other groups that the general recommendation should be to not participate in EA, at least financially. Yes, you should pay off your student loans (listen to Dave Ramsey). Many people who think they are in category (2) are really in this category.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;go-do-something-interesting-and-valuable&#34;&gt;Go do something interesting and valuable.&lt;/h1&gt;
&lt;p&gt;My main message is to the folks in category 2. The standard effective altruism expected value calculation allows for uncertainty and hedging of risk across interventions but doesn&amp;rsquo;t bother to translate those to an individual person&amp;rsquo;s level.&lt;/p&gt;
&lt;p&gt;If what is ultimately a pretty small amount of money to the world but a large amount of money to you will help you start that next idea, build the next company, write the next book, create the next organization, start the next agency, etc, you should do it.&lt;/p&gt;
&lt;p&gt;Ignore the pocket calculators in the corner calculating how many (in expectation) QALYs are now somehow your fault. They aren&amp;rsquo;t.&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;re doing exactly what the financial backers of the EA movement themselves did: looking at investments to maximize &lt;em&gt;a combination of personal utility and global utility&lt;/em&gt;. The only difference is that the first variable goes to zero as you get richer.&lt;/p&gt;
&lt;p&gt;And if it really is the case that you&amp;rsquo;re at diminishing returns for personal utility, then you slip closer to category 1 and should consider EA as a way of optimizing a global contribution. I think EA&amp;rsquo;s primary mistake is conflating everyone to be in the same category when they&amp;rsquo;re obviously not.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://www.effectivealtruism.org/articles/introduction-to-effective-altruism&#34;&gt;https://www.effectivealtruism.org/articles/introduction-to-effective-altruism&lt;/a&gt;
[2] The EA forum has a red team contest for criticisms of EA. I was already planning to write a post like this, but the financial incentive helped get it out the door. &lt;a href=&#34;https://forum.effectivealtruism.org/posts/8hvmvrgcxJJ2pYR4X/announcing-a-contest-ea-criticism-and-red-teaming#How_to_apply&#34;&gt;https://forum.effectivealtruism.org/posts/8hvmvrgcxJJ2pYR4X/announcing-a-contest-ea-criticism-and-red-teaming#How_to_apply&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href=&#34;http://www.paulgraham.com/say.html&#34;&gt;http://www.paulgraham.com/say.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] &lt;a href=&#34;https://astralcodexten.substack.com/p/effective-altruism-as-a-tower-of&#34;&gt;https://astralcodexten.substack.com/p/effective-altruism-as-a-tower-of&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[5] &lt;a href=&#34;https://www.effectivealtruism.org/articles/cause-profile-animal-welfare&#34;&gt;https://www.effectivealtruism.org/articles/cause-profile-animal-welfare&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[6] &lt;a href=&#34;https://michaelnotebook.com/eanotes&#34;&gt;https://michaelnotebook.com/eanotes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[7] &lt;a href=&#34;https://www.openphilanthropy.org/research/hits-based-giving/&#34;&gt;https://www.openphilanthropy.org/research/hits-based-giving/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[8] &lt;a href=&#34;https://80000hours.org/2021/08/effective-altruism-allocation-resources-cause-areas/&#34;&gt;https://80000hours.org/2021/08/effective-altruism-allocation-resources-cause-areas/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[9] The best quote in the Drake equation wikipedia article is the following: &amp;ldquo;Criticism of the Drake equation follows mostly from the observation that several terms in the equation are largely or entirely based on conjecture. Star formation rates are well-known, and the incidence of planets has a sound theoretical and observational basis, but the other terms in the equation become very speculative. The uncertainties revolve around our understanding of the evolution of life, intelligence, and civilization, not physics. No statistical estimates are possible for some of the parameters, where only one example is known. The net result is that the equation cannot be used to draw firm conclusions of any kind, and the resulting margin of error is huge, far beyond what some consider acceptable or meaningful.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;[10] For other good criticisms of EA, see: &lt;a href=&#34;https://whyphilanthropymatters.com/article/why-am-i-not-an-effective-altruist/&#34;&gt;https://whyphilanthropymatters.com/article/why-am-i-not-an-effective-altruist/&lt;/a&gt;
&lt;a href=&#34;https://forum.effectivealtruism.org/posts/xBBXf7KXZCKHYBxeZ/patrick-collison-on-effective-altruism&#34;&gt;https://forum.effectivealtruism.org/posts/xBBXf7KXZCKHYBxeZ/patrick-collison-on-effective-altruism&lt;/a&gt;
&lt;a href=&#34;https://freddiedeboer.substack.com/p/effective-altruism-has-a-novelty&#34;&gt;https://freddiedeboer.substack.com/p/effective-altruism-has-a-novelty&lt;/a&gt;&lt;/p&gt;
</description> 
    </item>
    
    <item>
      <title>Bandwidth of communication</title>
      <link>https://ssaraf.com/bandwidth/</link>
      <pubDate>Fri, 20 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://ssaraf.com/bandwidth/</guid>
      <description>&lt;p&gt;People know how the medium of conversation affects the discussion itself. For example, if you have a high number of back-and-forth messages with someone over Slack, you might suggest a quick video chat to delve more deeply into the issue. More information can be conveyed, faster, with a Zoom conversation. But what if neither party had suggested a video conference? Would we realize we were trapped in surface-level conversation?&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not intuitive that the properties of a signal will affect its message, but they do. As different communication mediums emerge, we need to understand the implications.&lt;/p&gt;
&lt;p&gt;Fortunately, the terms electrical engineers use do seem to translate over fairly well to human-human communication:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bandwidth - how much information can be conveyed in one message&lt;/li&gt;
&lt;li&gt;frequency - how often can you convey it&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think bandwidth and frequency explain the relationship between email and slack.&lt;/p&gt;
&lt;p&gt;Slack is lower bandwidth than email - while you can write a paragraph in slack, you can write much longer memos over email. But slack is intrinsically much higher frequency. It&amp;rsquo;s not unusual to slack someone 10 times a day. For two people who want to communicate normally, slack is preferable to email, because the &amp;ldquo;speed&amp;rdquo; is closer to regular conversation. For memos, where a large amount of communication is sent at once, email is preferable.&lt;/p&gt;
&lt;p&gt;So Slack has high frequency, low bandwidth, and email has low frequency, high bandwidth.&lt;/p&gt;
&lt;p&gt;Theoretically, you could have any conversation with any tool. Practically, which mechanism you use affects not just how much and how fast you can convey things, but what things you discuss at all.&lt;/p&gt;
&lt;p&gt;One observation I&amp;rsquo;ve had coming out of the pandemic is that meeting up with a coworker in person is a very alien experience! We talk more deeply about the subject at hand, and I have far more &amp;ldquo;a ha&amp;rdquo; moments in person than I ever do over zoom. That seems to imply that there were fewer such moments before.&lt;/p&gt;
&lt;p&gt;The contrast wasn&amp;rsquo;t as obvious in a world where all interactions had to happen over zoom. But now that in-person is an option, it&amp;rsquo;s clear that &amp;ldquo;live&amp;rdquo; discussions convey even more information than Zoom does, faster.&lt;/p&gt;
&lt;p&gt;You can have more frequent zooms, but the one in-person discussion you have will achieve far more. &lt;strong&gt;In-person discussion, unlike any other communication form, is &lt;em&gt;both&lt;/em&gt; high frequency and high bandwidth.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s bad news for remote workers, whose standard argument is that you can provide the same value from afar as you can in person. The raw math of commuting meant that working remotely &lt;em&gt;seemed&lt;/em&gt; more efficient in terms of hours worked. But while that may be true for solitary pursuits, building software often requires a lot of interaction. Those extra hours are a lot less efficient in the grand scheme of things.&lt;/p&gt;
&lt;p&gt;Can we measure bandwidth/frequency of communication in a conversation more directly? I think we can.&lt;/p&gt;
&lt;p&gt;Imagine you&amp;rsquo;re in a meeting with someone over zoom about a particularly important business problem, but, in the middle of your conversation, their audio gets filled with background noise from nearby construction.&lt;/p&gt;
&lt;p&gt;What is the likelihood that you continue discussing the problem in-depth? Do you try to explain a more abstract concept that underlies the problem?&lt;/p&gt;
&lt;p&gt;For me, the answer is no. I&amp;rsquo;ll more commonly surf to another topic of conversation that can be covered better even with impaired communication. For example, I might talk more if I think the other person can hear me okay, but can&amp;rsquo;t speak as easily.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s like the old way of getting out of a phone conversation. You grab a candy wrapper and crinkle it next to the mouthpiece&amp;hellip;&amp;ldquo;oh it&amp;rsquo;s hard to hear you so I&amp;rsquo;ll call you later&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;What about frequency? Imagine you&amp;rsquo;re meeting regularly with a team that works 10 timezones away. You&amp;rsquo;re constrained in &lt;em&gt;when&lt;/em&gt; you can talk to the team because the working hours hardly overlap. Thus you reduce the number of meetings you have.&lt;/p&gt;
&lt;p&gt;Framed this way, communication issues show up everywhere. How about that meeting where 10 people have their video on and 1 random guy has called in via phone? I guarantee rando isn&amp;rsquo;t speaking nearly as much in the forthcoming discussion. What about a 5 person meeting in a room, with one person over zoom?&lt;/p&gt;
&lt;p&gt;The danger with different communication protocols isn&amp;rsquo;t about the &lt;em&gt;efficiency&lt;/em&gt; of the communication, it&amp;rsquo;s about whether certain topics are discussed in-depth at all. If there&amp;rsquo;s some deep insight to be gleaned, it seems like it can only be gleaned in a relaxed, shared, in-person atmosphere, with time for (at least) two people to think. I don&amp;rsquo;t seem to ever get that over zoom or slack.&lt;/p&gt;
&lt;p&gt;People who only work remotely might be just as capable, but they might be trapped in the shallow end of the pool. When everyone was in the shallow end, no one knew the difference, but as we return to in-office work, the gap will be magnified. Maybe most worryingly, coworkers won&amp;rsquo;t know to blame the communication medium - they&amp;rsquo;ll instead assume incompetence or lack of context or any of the other usual talking points. It&amp;rsquo;ll seem coincidental that the people in the office &amp;ldquo;seem to know what&amp;rsquo;s going on&amp;rdquo; and the people on the outside &amp;ldquo;seem out of touch&amp;rdquo;. And what&amp;rsquo;s worse, those assessments might be true, in the sense that the in-office person is more likely to generate unique insights than the remote worker.&lt;/p&gt;
&lt;p&gt;Is there a good solution to this problem? I wonder if some of the newer tech, where users are in the same &amp;ldquo;virtual room&amp;rdquo; for long periods, would allow the sort of depth that is achievable so easily at the water cooler. Until then, it may be prudent to consider lower bandwidth communication as a kind of handicap - and defer deep conversations to the next high bandwidth opportunity.&lt;/p&gt;
</description> 
    </item>
    
    <item>
      <title>Crypto in the cave</title>
      <link>https://ssaraf.com/crypto_in_the_cave/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ssaraf.com/crypto_in_the_cave/</guid>
      <description>&lt;p&gt;Crypto seems to be a great divider amongst my friends and colleagues. Some think of it as the next step in human innovation, the future of finance, a political and social movement, and so on.&lt;/p&gt;
&lt;p&gt;Others, including myself, see it as a horrible mixture of &lt;a href=&#34;https://www.stephendiehl.com/blog/ponzi.html&#34;&gt;Ponzi scheme&lt;/a&gt;, MLM campaign, and suicide cult.&lt;/p&gt;
&lt;p&gt;From a technical perspective, it doesn&amp;rsquo;t seem to provide much utility over existing solutions - no software engineer chooses a ledger over, say, a database. You will have a hard time finding a company &amp;ldquo;built on crypto&amp;rdquo; that is not in some way also selling crypto.&lt;/p&gt;
&lt;p&gt;From a financial perspective, it seems to be a way of avoiding  regulation (and is thus a great place to take old financial tactics like wash trading and re-use them on a new generation of fools). Since bitcoin and its ilk don&amp;rsquo;t represent economic activity like stocks / bonds, it seems that its only intrinsic value is to sell it to someone who thinks they can sell it for more.&lt;/p&gt;
&lt;p&gt;Some folks compare investing in crypto to investing in gold. But I think investing in gold is stupid too - it only makes sense as a hedge against other trades. Crypto is correlated with the market, but more volatile, so would make a bad hedge.&lt;/p&gt;
&lt;p&gt;The only thing crypto seems to do well is enrich a small group of people who created whatever token / NFT thing is popular, and a larger group of VCs and tech companies &amp;ldquo;selling shovels&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;That said, gold, like stocks and everything else at the moment, trades far above intrinsic value. Why not have a meme token that trades for more than the market caps of half the S&amp;amp;P?&lt;/p&gt;
&lt;p&gt;But, while I think crypto is stupid, I could be wrong. My point isn&amp;rsquo;t about crypto specifically, but about why my friends disagree about it.&lt;/p&gt;
&lt;p&gt;People I know used to segment the way you&amp;rsquo;d expect if you were a political reporter in the early 2000s.&lt;/p&gt;
&lt;p&gt;There was the city dwelling, tech / finance / law / medicine working, IPA-drinking, educated crowd. They&amp;rsquo;d invite people to dinner parties with multiple appetizers. They only vaguely cared about sports. They voted for Democrats until they get rich, after which they became libertarian.&lt;/p&gt;
&lt;p&gt;Then there was the &amp;ldquo;flyover country&amp;rdquo; dwelling, blue collar job working, gun wielding, street smart crowd. They&amp;rsquo;d have kids early. They&amp;rsquo;d have barbeques and watch football. They voted for Republicans as a rule but only vaguely cared about politics.&lt;/p&gt;
&lt;p&gt;For more thoughts on these two groups, see this &lt;a href=&#34;https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/&#34;&gt;excellent piece&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Doesn&amp;rsquo;t the above seem incredibly old fashioned? The first is now a &amp;ldquo;woke mob&amp;rdquo; who will very carefully eat &amp;ldquo;organic&amp;rdquo; food and have strong opinions about gender identification on your Zoom username, and the second proudly wears MAGA hats but not face masks and has strong opinions about post-op trans women using female bathrooms.&lt;/p&gt;
&lt;p&gt;If this was just about political polarization, that would be one thing. But now the reality distortion field of the most recent elections seem to have rubbed off on everything else. Crypto is the latest example of many in which the questions are crazy, and up is down, and black is white. In fact, conversations about almost anything are nerve-wracking - even writing the above makes me worry about either being cancelled or summoning some type of red-hat mob.&lt;/p&gt;
&lt;p&gt;And the worst thing is that, generally speaking, I don&amp;rsquo;t care about most of it. I agree that much of it is important to other people. But not to me, except in the vague sense of wanting to talk about something other than the weather - these subjects come up most often in conversation. I feel guilty about not caring enough.&lt;/p&gt;
&lt;p&gt;For topics that I do care about, I see a streak of subjective, anecdotal, vague thinking which is worrisome, since it seems to be coming from all angles.&lt;/p&gt;
&lt;p&gt;For example, in my very left-leaning city, many (if not all) restaurants will have an indoor &amp;ldquo;mask on&amp;rdquo; policy. Aerosolized viruses transmit just fine while you&amp;rsquo;re eating - putting the mask on while talking but taking it off to eat food is stupid. If you&amp;rsquo;re going to take the mask off to eat, keep it off. Or don&amp;rsquo;t serve food indoors.&lt;/p&gt;
&lt;p&gt;Most of the current administration&amp;rsquo;s tactics around school closures, giving vaccines to children, etc have erred irrational. This leads parents to do well-justified things like smuggle their 11 and 4 year old kids to get the vaccine earlier than they &amp;ldquo;should&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;On the right, there&amp;rsquo;s too many examples to name. Perhaps the proud anti-vax and anti-mask groups are the easiest to pick on.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m reminded of the allegory of the cave. We&amp;rsquo;re all seeing shadows on the wall, and nobody knows what&amp;rsquo;s real.&lt;/p&gt;
&lt;p&gt;If you wanted to find out the truth about crypto, where would you go? Who would you ask? If you wanted to find the truth about vaccine effectiveness, where would you read it?&lt;/p&gt;
&lt;p&gt;I think the problem is that no one knows. There is no authority that can be trusted to give accurate, practical answers to these questions. The CDC, the standard authority, will give accurate but not risk-adjusted recommendations. For example, &lt;a href=&#34;https://www.latimes.com/science/story/2021-07-27/timeline-cdc-mask-guidance-during-covid-19-pandemic&#34;&gt;early in the pandemic&lt;/a&gt;  they were wrong about the utility of masks.&lt;/p&gt;
&lt;p&gt;Some &lt;a href=&#34;https://twitter.com/zeynep&#34;&gt;prominent folks&lt;/a&gt; will give closer to optimal recommendations, but their voices are diluted along with all the other loud people, and the reason they have a voice is, forgive me, they&amp;rsquo;re good at social media. Do we really think that the best authority on any subject is the one that emerges from the cauldron there? Or are we just picking the top dog in a mangy pack? For every Zeynep there is a Joe Rogan, and we can&amp;rsquo;t ignore that they emerged in the last few years in roughly the same way. How do we know which is which?&lt;/p&gt;
&lt;p&gt;It isn&amp;rsquo;t enough to &amp;ldquo;study the science&amp;rdquo; either. You can read &lt;a href=&#34;https://astralcodexten.substack.com/p/ivermectin-much-more-than-you-wanted&#34;&gt;here&lt;/a&gt; about a detailed meta-analysis on ivermectin, with the conclusion that it &lt;em&gt;might&lt;/em&gt; help patients with COVID, so long as they&amp;rsquo;re in a country where the populace has worms and therefore a dewormer helps improve clinical outcomes.&lt;/p&gt;
&lt;p&gt;My point isn&amp;rsquo;t the specific conclusion but the type of analysis that&amp;rsquo;s needed to interpret even a &lt;strong&gt;meta analysis&lt;/strong&gt; of scientific studies on a subject of immense practical value to all of humanity for the last two years. No one could possibly have the time to do the &amp;ldquo;from first principles&amp;rdquo; analytical approach in every area, so you have to read some one else&amp;rsquo;s summary, and right there you&amp;rsquo;re depending on that person&amp;rsquo;s credibility and platform.&lt;/p&gt;
&lt;p&gt;Before now, credibility and platform were determined by a small group of elite institutions, on both the left and right. The WSJ and NYT would &lt;em&gt;retract incorrect pieces&lt;/em&gt; if they were found to be misleading in even the smallest way. Scientific studies were published in prominent journals, and you would suffer professional consequences if you put something inaccurate in a paper.&lt;/p&gt;
&lt;p&gt;People who succeeded at those institutions were academically or professionally qualified, so you could trust what you read. And while those organizations still exist in today&amp;rsquo;s discourse, it feels like they&amp;rsquo;re drowned out from the mass of loud voices on more &amp;ldquo;decentralized&amp;rdquo; platforms like Twitter, Substack, Youtube, etc.&lt;/p&gt;
&lt;p&gt;No one issues a &amp;ldquo;retraction&amp;rdquo; on Twitter, unless the mob comes after them. And even in those circumstances, the person recanting isn&amp;rsquo;t doing so because of what&amp;rsquo;s factually accurate.&lt;/p&gt;
&lt;p&gt;And so rather than accuracy or truth we go for who can say the most interesting things, or the funniest jokes, or who can build an audience, which are different sorts of skill sets. You can&amp;rsquo;t even find the humble truth-seekers because these platforms only throw popular people at you to follow, not those poor shmucks tweeting to &amp;lt;100 friends.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s in that world where people are making new digital currencies and the mob is buying them up and they go up in value and more people join the mob to get in on the action, and soon you have an NFT of a picture of Elon Musk worth more money than can even be conceived of, but doesn&amp;rsquo;t do anything except reflect its own ever-increasing demand and fixed supply.&lt;/p&gt;
&lt;p&gt;Crypto can go to the moon, for all I care. I wish those people well. But I want a place to read about it that will put facts above whatever religion they&amp;rsquo;ve adopted. I worry that I have my own blind spots - things that I believe that aren&amp;rsquo;t really true, but I&amp;rsquo;m in a weird self-reinforcing bubble that makes me believe them stronger and stronger. And I&amp;rsquo;m not sure where to go.&lt;/p&gt;
</description> 
    </item>
    
    <item>
      <title>Building a personal brand</title>
      <link>https://ssaraf.com/building_a_personal_brand/</link>
      <pubDate>Sun, 21 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ssaraf.com/building_a_personal_brand/</guid>
      <description>&lt;p&gt;&lt;em&gt;One logistical update - I&amp;rsquo;ve centralized the posts that would usually go to the sudopoint or SQL blog to this one. If you were subscribed to sudopoint or on my SQL class mailing list, you&amp;rsquo;re now subscribed here.&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I&amp;rsquo;m surprised to see many of my friends starting to build public online presences. Previously they didn&amp;rsquo;t seem to want to. Why?&lt;/p&gt;
&lt;p&gt;Part of the reason seems to be that many of them are starting companies, and CEOs often have to do a lot of marketing. Without a pre-existing marketing machine, they try to bootstrap one from their personal social accounts.&lt;/p&gt;
&lt;p&gt;But I think it&amp;rsquo;s more than that, and I think there&amp;rsquo;s a link to some of the earlier thoughts on this blog related to &lt;a href=&#34;https://ssaraf.com/keynesian_workweek&#34;&gt;work week&lt;/a&gt;, and building &lt;a href=&#34;https://ssaraf.com/side_projects&#34;&gt;side projects&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We are each our own little company now.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;That converts &amp;ldquo;full time employment&amp;rdquo; into something that looks a lot more like one larger company subcontracting work to a smaller company (You Inc).&lt;/p&gt;
&lt;p&gt;It also explains why employers increasingly are looking to reduce global benefits in favor of those that the individual employee can decide how to wrangle. Instead of insurance benefits, pay enough salary that employees can buy on the exchange. Instead of dumbbells in the office, a stipend for doing whatever workouts you want. Instead of 8 hours a day each day, spend however much time you need to get the job done.&lt;/p&gt;
&lt;p&gt;It also explains why &lt;em&gt;getting&lt;/em&gt; a job is such a weird experience. Almost no one who gets a job gets it by applying for it via a website. Instead it&amp;rsquo;s about relationships you&amp;rsquo;ve built - effectively, how well you can market yourself as the best subcontractor for the position. Sure, the company doesn&amp;rsquo;t &lt;em&gt;call you&lt;/em&gt; a contractor, but you can end the contract tomorrow and go start another one, just like a contractor can.&lt;/p&gt;
&lt;p&gt;Gig economy workers already knew about all of this, of course. But this emerging independence has usually been painted as primarily an advantage to employers, who get away with providing fewer perks to a captive employment base. I think the opposite - this is an advantage, though largely unexploited, for employees.&lt;/p&gt;
&lt;p&gt;For example, there&amp;rsquo;s a large &lt;a href=&#34;https://overemployed.com/&#34;&gt;community of people&lt;/a&gt; that now work two &amp;ldquo;full time&amp;rdquo; jobs. For those of us just working the one, we know that it&amp;rsquo;s perfectly possible (in fact, likely) that you only get 10 or 20 hours of productive work in for an employer per week. For highly circumscribed roles, with concrete independent deliverables (i.e. non management), getting multiple jobs is a brilliant approach to maximize your income.&lt;/p&gt;
&lt;p&gt;Meanwhile, successful companies are getting smaller. And not just startups - I mean regular companies can be built &amp;ldquo;off the shelf&amp;rdquo; and so simply require fewer personnel to get a product to market. The rise of the Indie Hacker movement has been astronomical, and I think will only continue to swell. Journalists are leaving newspapers to start substacks, where they can earn money directly, on their own.&lt;/p&gt;
&lt;p&gt;I suspect that the maximally employable people will be those that take advantage of this structure to market themselves effectively. The main problem is that most of the people I know doing this are, bluntly, super boring.&lt;/p&gt;
&lt;p&gt;I occasonally peruse twitter, and even the &amp;ldquo;intelligent tech&amp;rdquo; people are primarily posting what I would consider to be absolute drivel. Epigrams that would drive Confucius crazy. Statements that seem controversial but are really just paper thin assessments of the obvious. They are effectively text-only rorschach images meant to get forwarded around as simply the next version of chain letters.&lt;/p&gt;
&lt;p&gt;Most of these posters are pretty thoughtful people, many of whom are brilliant writers. But they need to use twitter / linkedin / facebook as sort of a marketing mechanism to catch a little bit of attention from the vast sea of internet fish. Which they then funnel into whatever scheme they&amp;rsquo;re peddling - youtube channels, substack subscriptions, try my startup, etc.&lt;/p&gt;
&lt;p&gt;This blog isn&amp;rsquo;t an exception, but I can at least be honest about that.&lt;/p&gt;
&lt;p&gt;More importantly, I think it has implications for those of you reading who don&amp;rsquo;t already have an online presence. All signs point to you being at a disadvantage compared to those who have shamelessly sleazed themselves out on social media. Probably not in your current role, but certainly when looking for a new one, or starting a project that requires a global audience.&lt;/p&gt;
&lt;p&gt;And yet, the people who I most respect in my past workplaces, who are often the wisest, most thoughtful people, they often have no meaningful online persona. They don&amp;rsquo;t link to tweets. They barely watch youtube. As far as I can tell, many of them don&amp;rsquo;t even have linkedin profiles.&lt;/p&gt;
&lt;p&gt;That makes me think that as loud and obnoxious as the current online discourse is, the vast majority of people in real life are not writing online at all, and most (especially the most talented and experienced) are barely reading it. They know it&amp;rsquo;s mostly crap.&lt;/p&gt;
&lt;p&gt;Perhaps it is still early in the game. I wonder if participating in it will actually be an advantage, or instead an indicator of which people clumsily jumped into a fad that will eventually fade.&lt;/p&gt;
</description> 
    </item>
    
  </channel>
</rss>